# rock-paper-scissors-classification

This rock paper scissors classification CNN is a machine learning model that has been trained to recognize and classify hand gestures of rock, paper, and scissors.
It was built using the popular deep learning framework TensorFlow, the high-level neural networks API Keras, and the computer vision library OpenCV.
The model has been able to achieve a test accuracy of 91%, which is a very good performance.


The model utilizes a convolutional neural network (CNN) architecture, which is known to be effective in image classification tasks. 
The CNN consists of multiple layers that extract features from the input images and ultimately make a prediction about the class of the image. 
The model was trained on a dataset of images of hand gestures, and it has been able to achieve a high accuracy in classifying the images.



The trained model can be used for real-time hand gesture recognition and classification using OpenCV for computer vision. 
To try it out for yourself, run the classifcation.py to run the livetime image recognition.

![image](https://user-images.githubusercontent.com/92134792/212753632-864a4225-0462-4c6f-94de-434b64f47af1.png)


In summary, this rock paper scissors classification CNN is a powerful model that can be applied to a variety of use-cases. 
It is built using TensorFlow, Keras, and OpenCV, and it is trained on a dataset of images of hand gestures. With the ability to achieve a high accuracy in classifying the images, the model can be used for real-time hand gesture recognition and classification. 
